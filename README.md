# LightSaber_AR
MediaPipeとOpenCVを用いたWebARコンテンツの作成

## こだわりポイント
# ライトセイバーが立ち上がる時の効果音を実装した。
手のトラッキング結果(landmarks)から必要な要素を選択し、親指が立ち上がっている状態を判定
→立ち上がりの割合を算出し、一定の値以上の場合にSEを発火させる。
→フレームレートに準じて何回も同じ音が出ないようにflagを用意して、適切なSE発火処理をする

# 横に降った時の効果音を左右別々で実装した。
landmarksのうち親指の先(4番)に着目して左右判定と移動量判定する
→フレームレート単位で値を取ると読み取り誤差も拾ってしまう、値が細かすぎるなどの支障が出るので、10フレームごとに値を取得するようにした。
→landmarkのx座標を拾って左右の移動判定、xyから移動距離を出す
→一定値以上の場合、左右ごとに異なるSEを発火。

# かめはめ波も実装した
・かめはめ波の手の形を観察し、両手首と両指先のそれぞれの距離の比率で発火ポイントを決めた。
・openCVで楕円形を重ね合わせで、中心位置とサイズを取っている。
・TODO 第４象限に打つと手前に帰ってきてしまうので、角度の調整が必要。

### これから追加したい機能
・MediaPipeの顔認証を使って、口を認識したらマイクモードに入るようにする(ボタン式じゃなくする)
・音声「はいチーズ」からの記念撮影(html2canvas画面キャプチャ)機能

### 元々ついていたけど削った機能
・Web Speech APIで音声認識からの発火を実装していたが、グダる要因になるのとUIがあまり良くなかったので取り消し。
・作成ファイルは"voiceRrec.js"として保存してあります。